# InstructPix2Pix æ¨¡å‹è®­ç»ƒé¡¹ç›®

æœ¬é¡¹ç›®ç”¨äºè®­ç»ƒ InstructPix2Pix æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®æ–‡æœ¬æŒ‡ä»¤å¯¹å›¾åƒè¿›è¡Œç¼–è¾‘ã€‚

## ğŸ—‚ï¸ ä»£ç ä¸å¤§æ–‡ä»¶æ‹†åˆ†ç­–ç•¥

> GitHub ä»“åº“ä»…æäº¤å¯å¤ç°çš„ä»£ç ä¸é…ç½®ï¼›æ‰€æœ‰æ•°æ®é›†ã€æ¨¡å‹æƒé‡ã€è®­ç»ƒè¾“å‡ºç»Ÿä¸€æ‰˜ç®¡åœ¨å¤–éƒ¨å­˜å‚¨ï¼ˆHugging Face Hub / OSS / ç™¾åº¦ç½‘ç›˜ï¼‰ï¼Œä»¥é¿å… 100GB çº§åˆ«èµ„äº§è¢«æ¨é€åˆ° GitHubã€‚

- `.gitignore` å·²å¿½ç•¥ä»¥ä¸‹ç›®å½•/æ–‡ä»¶ï¼š`dataset_root/`ã€`dataset_mini/`ã€`processed_dataset_seq/`ã€`models/`ã€`output_video_model/`ã€`test_output/`ã€`dataset_root.zip` ç­‰ã€‚å¼€å‘è€…æœ¬åœ°å¯ç…§å¸¸ä½¿ç”¨è¿™äº›ç›®å½•ï¼Œä½†åœ¨ Git æäº¤å‰æ— éœ€å…³å¿ƒå…¶çŠ¶æ€ã€‚
- è‹¥éœ€è¦æ¢å¤æˆ–åˆ†äº«æ•°æ®ï¼Œè¯·æŒ‰ç…§ä¸‹é¢ä»»ä¸€æ¸ é“ä¸‹è½½ï¼Œç„¶åè§£å‹/è¦†å†™åˆ°å¯¹åº”è·¯å¾„å³å¯ã€‚

### å¤–éƒ¨èµ„äº§æ±‡æ€»

| èµ„äº§ | æè¿° | æ¨èå­˜å‚¨ | å¤‡æ³¨ |
| --- | --- | --- | --- |
| `dataset_root` | å®Œæ•´åŸå§‹è§†é¢‘æ•°æ®ï¼ˆtrain/val/testï¼‰ | Hugging Face Datasetsï¼š`https://huggingface.co/datasets/<org>/dl-final-dataset` | ä¸Šä¼  `dataset_root.zip` å¹¶åœ¨ README ä¸­è®°å½•ç‰ˆæœ¬ |
| `processed_dataset_seq` | Arrow å¤šå¸§åºåˆ—æ•°æ®é›† | åŒä¸Šï¼ˆä¹Ÿå¯æ”¾ OSSï¼‰ | è¿è¡Œ `make_dataset.py` åæ‰“åŒ…ä¸Šä¼  |
| `models/instruct-pix2pix`ã€`models/instruct-pix2pix-video-20frames` | é¢„è®­ç»ƒ + 84 é€šé“å®šåˆ¶ UNet | Hugging Face Modelsï¼š`https://huggingface.co/<org>/dl-final-models` | ä¹Ÿå¯ä½¿ç”¨ `python download_model.py` é‡æ–°ä¸‹è½½ |
| `output_video_model/`ã€`test_output/` | è®­ç»ƒ checkpointã€TensorBoard æ—¥å¿— | OSSï¼š`oss://<bucket>/dl-final/checkpoints/` | ä»…ä¿ç•™æœ€è¿‘è‹¥å¹²ç‰ˆæœ¬ |
| `dataset_mini/`ã€`dataset_root.zip` | è°ƒè¯•ç”¨è¿·ä½ æ•°æ® & æ•°æ®å‹ç¼©åŒ… | ç™¾åº¦ç½‘ç›˜åˆ†äº«é“¾æ¥ | æ–¹ä¾¿å¯¹å¤–åä½œæˆ–æ— æ³•è®¿é—® HF/OSS çš„åŒå­¦ |

> å°† `<org>`ã€`<bucket>`ã€`<share-id>` ç­‰å ä½ç¬¦æ›¿æ¢ä¸ºå›¢é˜Ÿå®é™…å€¼ï¼›å½“å¤–éƒ¨é“¾æ¥å˜æ›´æ—¶ï¼Œè¯·åŒæ­¥æ›´æ–°æœ¬èŠ‚å†…å®¹ã€‚

### ä¸‹è½½æ–¹å¼ç¤ºä¾‹

#### 1. Hugging Face Hubï¼ˆä¸»æ¸ é“ï¼‰

```bash
pip install huggingface_hub[cli]
huggingface-cli login  # ä½¿ç”¨æ‹¥æœ‰ <org>/dl-final-* æƒé™çš„è´¦å·
export HF_ENDPOINT=https://hf-mirror.com  # å¦‚éœ€åŠ é€Ÿï¼Œå¯æ”¹ä¸ºå®˜æ–¹ç«™ç‚¹

# æ•°æ®é›†
huggingface-cli download <org>/dl-final-dataset \
  --repo-type dataset \
  --local-dir ./dataset_root_sync
rsync -a dataset_root_sync/dataset_root ./dataset_root

# æ¨¡å‹ / æ£€æŸ¥ç‚¹
huggingface-cli download <org>/dl-final-models \
  --local-dir ./models_sync \
  --include "models/**" "output_video_model/**"
rsync -a models_sync/models ./models
rsync -a models_sync/output_video_model ./output_video_model
```

æ›´å¤š Hugging Face ç›¸å…³è¯´æ˜å¯å‚è€ƒ [`MODEL_DOWNLOAD.md`](MODEL_DOWNLOAD.md) ä¸ `download_model.py`ã€‚

#### 2. é˜¿é‡Œäº‘ OSSï¼ˆå†…ç½‘å¤‡ä»½ï¼‰

```bash
# é¦–æ¬¡ä½¿ç”¨éœ€æ‰§è¡Œ ossutil configï¼Œå¡«å…¥ <bucket> çš„ endpoint ä¸ AK ä¿¡æ¯
ossutil cp -r oss://<bucket>/dl-final/dataset_root ./dataset_root
ossutil cp -r oss://<bucket>/dl-final/processed_dataset_seq ./processed_dataset_seq
ossutil cp -r oss://<bucket>/dl-final/output_video_model ./output_video_model
```

#### 3. ç™¾åº¦ç½‘ç›˜ï¼ˆä¾¿æ·åˆ†äº«ï¼‰

```
é“¾æ¥ï¼šhttps://pan.baidu.com/s/<share-id>
æå–ç ï¼š<code>
å†…å®¹ï¼šdataset_root.zipã€processed_dataset_seq.tarã€output_video_model-checkpoint-***.zip
```

ä¸Šè¿°é“¾æ¥é€‚ç”¨äºæ— æ³•è®¿é—® HF/OSS çš„åä½œè€…ï¼Œå¯æ ¹æ®éœ€è¦æ›¿æ¢ä¸ºæœ€æ–°åˆ†äº«åœ°å€ã€‚

## ğŸ“Š é¡¹ç›®è¿›å±•

### âœ… å·²å®Œæˆ

- [x] **ç¯å¢ƒé…ç½®**
  - Conda ç¯å¢ƒå·²åˆ›å»ºå¹¶é…ç½®ï¼ˆdl-finalï¼‰
  - æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…ï¼ˆrequirements.txtï¼‰
  - Protobuf å…¼å®¹æ€§é—®é¢˜å·²ä¿®å¤

- [x] **æ¨¡å‹å‡†å¤‡**
  - é¢„è®­ç»ƒæ¨¡å‹å·²ä¸‹è½½ï¼ˆä½¿ç”¨ HF-Mirror é•œåƒç«™ç‚¹ï¼‰
  - æ¨¡å‹å¤§å°ï¼šçº¦ 2.4GBï¼ˆåŒ…å« UNet, VAE, Text Encoder ç­‰ï¼‰
  - æ¨¡å‹è·¯å¾„ï¼š`dl-final/models/instruct-pix2pix`

- [x] **æ•°æ®é›†å‡†å¤‡**
  - æ•°æ®é›†å·²è§£å‹å¹¶æ•´ç†ï¼ˆdataset_root.zipï¼‰
  - è®­ç»ƒé›†ï¼š1500 ä¸ªæ ·æœ¬ï¼ˆ3ä¸ªä»»åŠ¡ç±»å‹ï¼šdrop_object, cover_object, move_objectï¼‰
  - éªŒè¯é›†ï¼šå·²å‡†å¤‡
  - æµ‹è¯•æ•°æ®ï¼šå·²è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼ï¼ˆtest_data/ï¼‰
  - è¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼šå·²åˆ›å»ºï¼ˆdataset_mini/ï¼‰ï¼Œç”¨äºå¿«é€ŸéªŒè¯æ•°æ®æµç¨‹
  - âœ… æ•°æ®é›†è½¬æ¢è„šæœ¬ï¼š`make_dataset.py`ï¼ˆæ”¯æŒå¤šå¸§è¾“å…¥åºåˆ—ï¼Œå­˜å‚¨å¸§è·¯å¾„å­—ç¬¦ä¸²ï¼‰
  - âœ… æ–°æ•°æ®é›†æ ¼å¼ï¼š`processed_dataset_seq`ï¼ˆHuggingFace Arrow æ•°æ®é›†ï¼Œ`input_frames` åºåˆ—å…ƒç´ ä¸ºå¸§è·¯å¾„ï¼‰

- [x] **è®­ç»ƒè„šæœ¬**
  - ä¸»è®­ç»ƒè„šæœ¬ï¼š`train_instruct_pix2pix.py`ï¼ˆå·²ä¿®å¤ç‰ˆæœ¬æ£€æŸ¥é—®é¢˜ï¼‰
  - æµ‹è¯•è®­ç»ƒè„šæœ¬ï¼š`test_training.sh`
  - æ•°æ®å‡†å¤‡è„šæœ¬ï¼š
    - `make_dataset.py`ï¼šå°†åŸå§‹æ•°æ®è½¬æ¢ä¸º HuggingFace Dataset æ ¼å¼ï¼ˆæ”¯æŒå¤šå¸§è¾“å…¥åºåˆ—ï¼‰
    - `prepare_test_data.py`ï¼šå‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆä» test_video è½¬æ¢ï¼‰
    - `create_mini_data.py`ï¼šåˆ›å»ºè¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ˆç”Ÿæˆéšæœºæµ‹è¯•å›¾ç‰‡ï¼‰
  - æ¨¡å‹ä¸‹è½½è„šæœ¬ï¼š`download_model.py`ï¼ˆæ”¯æŒé•œåƒç«™ç‚¹ï¼‰
  - âœ… æ–°å¢ `run_video_training.py`ï¼šçº¯ Python å…¥å£ï¼Œæ— éœ€å‘½ä»¤è¡Œå³å¯å¯åŠ¨å¤š GPU è®­ç»ƒ

- [x] **æµ‹è¯•éªŒè¯**
  - âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡ï¼ˆquick_test.pyï¼‰
  - âœ… æµ‹è¯•è®­ç»ƒæˆåŠŸå®Œæˆï¼ˆ5æ­¥è®­ç»ƒï¼‰
  - âœ… è®­ç»ƒæŸå¤±æ­£å¸¸ä¸‹é™ï¼ˆ0.626 â†’ 0.0134ï¼‰
  - âœ… æ£€æŸ¥ç‚¹ä¿å­˜æˆåŠŸï¼ˆcheckpoint-5ï¼‰
  - âœ… æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½å’Œè®­ç»ƒ

### ğŸš§ è¿›è¡Œä¸­

- [ ] **å®Œæ•´è®­ç»ƒ**
  - ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
  - è°ƒæ•´è¶…å‚æ•°ä»¥è·å¾—æœ€ä½³æ•ˆæœ
  - ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼ˆTensorBoard/WandBï¼‰

### ğŸ“‹ å¾…å®Œæˆ

- [ ] **æ¨¡å‹è¯„ä¼°**
  - åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
  - ç”Ÿæˆæ ·æœ¬å›¾åƒè¿›è¡Œå¯è§†åŒ–
  - è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ FID, IS ç­‰ï¼‰

- [ ] **æ¨¡å‹ä¼˜åŒ–**
  - è¶…å‚æ•°è°ƒä¼˜
  - å°è¯•ä¸åŒçš„è®­ç»ƒç­–ç•¥
  - æ¨¡å‹å‹ç¼©å’Œä¼˜åŒ–

- [ ] **æ–‡æ¡£å®Œå–„**
  - è®­ç»ƒç»“æœåˆ†æ
  - æœ€ä½³å®è·µæ€»ç»“
  - ä½¿ç”¨æ¡ˆä¾‹å’Œç¤ºä¾‹

### ğŸ“ˆ æµ‹è¯•è®­ç»ƒç»“æœ

**æµ‹è¯•è®­ç»ƒç»Ÿè®¡**ï¼ˆ2025-12-01ï¼‰ï¼š
- è®­ç»ƒæ­¥æ•°ï¼š5 æ­¥
- è®­ç»ƒæ—¶é—´ï¼š~29 ç§’
- åˆå§‹æŸå¤±ï¼š0.626
- æœ€ç»ˆæŸå¤±ï¼š0.0134
- å­¦ä¹ ç‡ï¼š1e-4
- æ‰¹æ¬¡å¤§å°ï¼š1
- åˆ†è¾¨ç‡ï¼š256x256
- çŠ¶æ€ï¼šâœ… æˆåŠŸ

**æ£€æŸ¥ç‚¹ä¿¡æ¯**ï¼š
- ä¿å­˜ä½ç½®ï¼š`test_output/checkpoint-5/`
- åŒ…å«ç»„ä»¶ï¼šUNet, Optimizer, Scheduler, Scaler
- æ–‡ä»¶å¤§å°ï¼š~6.5GBï¼ˆåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰

## ğŸ“‹ ç›®å½•ç»“æ„

```
dl-final/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ requirements.txt             # Python ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ MODEL_DOWNLOAD.md           # æ¨¡å‹ä¸‹è½½è¯¦ç»†è¯´æ˜æ–‡æ¡£
â”‚
â”œâ”€â”€ è®­ç»ƒç›¸å…³è„šæœ¬/
â”‚   â”œâ”€â”€ train_instruct_pix2pix.py   # ä¸»è®­ç»ƒè„šæœ¬ï¼ˆHuggingFace å®˜æ–¹ï¼‰
â”‚   â”œâ”€â”€ run_train.sh               # å®Œæ•´è®­ç»ƒå¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ test_training.sh            # æµ‹è¯•è®­ç»ƒè„šæœ¬ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
â”‚   â””â”€â”€ test_training_output.log    # æµ‹è¯•è®­ç»ƒæ—¥å¿—è¾“å‡º
â”‚
â”œâ”€â”€ æ•°æ®å‡†å¤‡è„šæœ¬/
â”‚   â”œâ”€â”€ prepare_test_data.py        # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆä» test_video è½¬æ¢ï¼‰
â”‚   â”œâ”€â”€ make_dataset.py             # æ•°æ®é›†åˆ¶ä½œè„šæœ¬
â”‚   â”œâ”€â”€ create_mini_data.py         # åˆ›å»ºè¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ˆç”Ÿæˆéšæœºæµ‹è¯•å›¾ç‰‡ï¼‰
â”‚   â””â”€â”€ quick_test.py               # å¿«é€Ÿæ•°æ®æ ¼å¼éªŒè¯è„šæœ¬
â”‚
â”œâ”€â”€ å·¥å…·è„šæœ¬/
â”‚   â”œâ”€â”€ download_model.py           # æ¨¡å‹ä¸‹è½½è„šæœ¬ï¼ˆæ”¯æŒé•œåƒç«™ç‚¹ï¼‰
â”‚   â””â”€â”€ setup_mirror.sh             # HuggingFace é•œåƒç«™ç‚¹è®¾ç½®è„šæœ¬
â”‚
â”œâ”€â”€ src/                          # æºä»£ç ç›®å½•ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ dataset.py                 # æ•°æ®é›†å¤„ç†æ¨¡å—
â”‚   â””â”€â”€ train.py                   # è®­ç»ƒæ¨¡å—
â”‚
â”œâ”€â”€ dataset_root/                 # æ•°æ®é›†æ ¹ç›®å½•
â”‚   â”œâ”€â”€ metadata.json              # æ•°æ®é›†å…ƒæ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰æ ·æœ¬ä¿¡æ¯ï¼‰
â”‚   â”œâ”€â”€ dataset_root.zip           # æ•°æ®é›†å‹ç¼©åŒ…ï¼ˆåŸå§‹æ•°æ®ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ train/                     # è®­ç»ƒæ•°æ®é›†
â”‚   â”‚   â”œâ”€â”€ drop_object/           # æ”¾ç½®ç‰©ä½“ä»»åŠ¡ï¼ˆ~400ä¸ªè§†é¢‘ï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ video_*/           # æ¯ä¸ªè§†é¢‘ä¸€ä¸ªç›®å½•
â”‚   â”‚   â”‚       â”œâ”€â”€ 00.jpg         # åŸå§‹å›¾åƒ
â”‚   â”‚   â”‚       â”œâ”€â”€ 01.jpg         # ç¼–è¾‘åå›¾åƒ
â”‚   â”‚   â”‚       â”œâ”€â”€ 02.jpg         # ä¸­é—´å¸§ï¼ˆå¦‚æœ‰ï¼‰
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ cover_object/           # è¦†ç›–ç‰©ä½“ä»»åŠ¡ï¼ˆ~400ä¸ªè§†é¢‘ï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ video_*/           # è§†é¢‘ç›®å½•ç»“æ„åŒä¸Š
â”‚   â”‚   â””â”€â”€ move_object/           # ç§»åŠ¨ç‰©ä½“ä»»åŠ¡ï¼ˆ~400ä¸ªè§†é¢‘ï¼‰
â”‚   â”‚       â””â”€â”€ video_*/           # è§†é¢‘ç›®å½•ç»“æ„åŒä¸Š
â”‚   â”‚
â”‚   â”œâ”€â”€ val/                       # éªŒè¯æ•°æ®é›†
â”‚   â”‚   â”œâ”€â”€ drop_object/           # æ”¾ç½®ç‰©ä½“éªŒè¯é›†
â”‚   â”‚   â”œâ”€â”€ cover_object/          # è¦†ç›–ç‰©ä½“éªŒè¯é›†
â”‚   â”‚   â””â”€â”€ move_object/           # ç§»åŠ¨ç‰©ä½“éªŒè¯é›†
â”‚   â”‚
â”‚   â”œâ”€â”€ test_video/                # æµ‹è¯•è§†é¢‘æ•°æ®ï¼ˆåŸå§‹ï¼‰
â”‚   â”‚   â”œâ”€â”€ 00.jpg                 # æµ‹è¯•åŸå§‹å›¾åƒ
â”‚   â”‚   â”œâ”€â”€ 01.jpg                 # æµ‹è¯•ç¼–è¾‘åå›¾åƒ
â”‚   â”‚   â””â”€â”€ test_video.json        # æµ‹è¯•è§†é¢‘å…ƒæ•°æ®
â”‚   â”‚
â”‚   â””â”€â”€ test_data/                 # å¤„ç†åçš„æµ‹è¯•æ•°æ®ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰
â”‚       â”œâ”€â”€ input_image.jpg        # è¾“å…¥å›¾åƒï¼ˆæ¥è‡ª test_video/00.jpgï¼‰
â”‚       â”œâ”€â”€ edited_image.jpg        # ç¼–è¾‘åå›¾åƒï¼ˆæ¥è‡ª test_video/01.jpgï¼‰
â”‚       â””â”€â”€ metadata.jsonl         # æµ‹è¯•æ•°æ®å…ƒæ•°æ®ï¼ˆHuggingFace æ ¼å¼ï¼‰
â”‚
â”œâ”€â”€ dataset_mini/                 # è¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ˆç¨‹åºç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ metadata.json             # æ•°æ®é›†å…ƒæ•°æ®
â”‚   â””â”€â”€ train/                    # è®­ç»ƒæ•°æ®
â”‚       â””â”€â”€ video_test_01/        # æµ‹è¯•è§†é¢‘ç›®å½•
â”‚           â”œâ”€â”€ 00.jpg            # ç¬¬1å¸§ï¼ˆè¾“å…¥ï¼‰
â”‚           â”œâ”€â”€ 01.jpg            # ç¬¬2å¸§
â”‚           â”œâ”€â”€ ...               # ä¸­é—´å¸§
â”‚           â””â”€â”€ 20.jpg            # ç¬¬21å¸§ï¼ˆç›®æ ‡è¾“å‡ºï¼‰
â”‚
â”œâ”€â”€ processed_dataset_seq/        # å¤„ç†åçš„æ•°æ®é›†ï¼ˆHuggingFace æ ¼å¼ï¼Œæ”¯æŒå¤šå¸§è¾“å…¥ï¼‰
â”‚   â”œâ”€â”€ dataset_dict.json        # æ•°æ®é›†å­—å…¸é…ç½®
â”‚   â”œâ”€â”€ train/                   # è®­ç»ƒé›†
â”‚   â”‚   â”œâ”€â”€ dataset_info.json    # æ•°æ®é›†ä¿¡æ¯ï¼ˆåŒ…å« features å®šä¹‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ state.json           # çŠ¶æ€ä¿¡æ¯
â”‚   â”‚   â””â”€â”€ data-*.arrow         # Arrow æ ¼å¼æ•°æ®æ–‡ä»¶
â”‚   â””â”€â”€ test/                    # æµ‹è¯•é›†ï¼ˆå¦‚æœæ•°æ®é‡è¶³å¤Ÿï¼‰
â”‚
â”œâ”€â”€ processed_dataset_mini_test/ # æ—§ç‰ˆå¤„ç†åçš„æ•°æ®é›†ï¼ˆå•å¸§è¾“å…¥æ ¼å¼ï¼‰
â”‚   â””â”€â”€ train/                   # è®­ç»ƒé›†
â”‚
â”œâ”€â”€ models/                       # æ¨¡å‹å­˜å‚¨ç›®å½•
â”‚   â””â”€â”€ instruct-pix2pix/         # InstructPix2Pix é¢„è®­ç»ƒæ¨¡å‹
â”‚       â”œâ”€â”€ README.md              # æ¨¡å‹è¯´æ˜æ–‡æ¡£
â”‚       â”œâ”€â”€ model_index.json       # æ¨¡å‹ç´¢å¼•æ–‡ä»¶
â”‚       â”‚
â”‚       â”œâ”€â”€ unet/                  # UNet æ¨¡å‹ï¼ˆæ ¸å¿ƒç»„ä»¶ï¼Œ~3.3GBï¼‰
â”‚       â”‚   â”œâ”€â”€ config.json        # UNet é…ç½®
â”‚       â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â”‚       â”‚
â”‚       â”œâ”€â”€ vae/                   # VAE ç¼–ç å™¨/è§£ç å™¨ï¼ˆ~300MBï¼‰
â”‚       â”‚   â”œâ”€â”€ config.json
â”‚       â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â”‚       â”‚
â”‚       â”œâ”€â”€ text_encoder/          # CLIP æ–‡æœ¬ç¼–ç å™¨ï¼ˆ~500MBï¼‰
â”‚       â”‚   â”œâ”€â”€ config.json
â”‚       â”‚   â””â”€â”€ model.safetensors
â”‚       â”‚
â”‚       â”œâ”€â”€ tokenizer/             # CLIP åˆ†è¯å™¨
â”‚       â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚       â”‚   â”œâ”€â”€ vocab.json
â”‚       â”‚   â””â”€â”€ merges.txt
â”‚       â”‚
â”‚       â”œâ”€â”€ scheduler/             # æ‰©æ•£è°ƒåº¦å™¨
â”‚       â”‚   â””â”€â”€ scheduler_config.json
â”‚       â”‚
â”‚       â”œâ”€â”€ safety_checker/        # å®‰å…¨æ£€æŸ¥å™¨ï¼ˆå¯é€‰ï¼‰
â”‚       â”‚   â””â”€â”€ model.safetensors
â”‚       â”‚
â”‚       â””â”€â”€ feature_extractor/     # ç‰¹å¾æå–å™¨
â”‚           â””â”€â”€ preprocessor_config.json
â”‚
â””â”€â”€ test_output/                  # æµ‹è¯•è®­ç»ƒè¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoint-5/              # è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆç¬¬5æ­¥ï¼‰
    â”‚   â”œâ”€â”€ unet/                  # è®­ç»ƒåçš„ UNet
    â”‚   â”œâ”€â”€ optimizer.bin          # ä¼˜åŒ–å™¨çŠ¶æ€
    â”‚   â”œâ”€â”€ scheduler.bin          # å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
    â”‚   â””â”€â”€ scaler.pt              # æ··åˆç²¾åº¦ç¼©æ”¾å™¨
    â”‚
    â”œâ”€â”€ logs/                      # è®­ç»ƒæ—¥å¿—
    â”‚   â””â”€â”€ instruct-pix2pix/      # TensorBoard æ—¥å¿—
    â”‚
    â”œâ”€â”€ unet/                      # æœ€ç»ˆè®­ç»ƒåçš„ UNet
    â”œâ”€â”€ vae/                       # VAEï¼ˆä»é¢„è®­ç»ƒæ¨¡å‹å¤åˆ¶ï¼‰
    â”œâ”€â”€ text_encoder/              # æ–‡æœ¬ç¼–ç å™¨ï¼ˆä»é¢„è®­ç»ƒæ¨¡å‹å¤åˆ¶ï¼‰
    â”œâ”€â”€ tokenizer/                 # åˆ†è¯å™¨ï¼ˆä»é¢„è®­ç»ƒæ¨¡å‹å¤åˆ¶ï¼‰
    â”œâ”€â”€ scheduler/                 # è°ƒåº¦å™¨ï¼ˆä»é¢„è®­ç»ƒæ¨¡å‹å¤åˆ¶ï¼‰
    â””â”€â”€ model_index.json           # æ¨¡å‹ç´¢å¼•æ–‡ä»¶
```

### å…³é”®ç›®å½•è¯´æ˜

- **dataset_root/train/**: åŒ…å«ä¸‰ä¸ªä»»åŠ¡ç±»å‹çš„è®­ç»ƒæ•°æ®ï¼Œæ¯ä¸ªä»»åŠ¡çº¦400ä¸ªè§†é¢‘æ ·æœ¬
- **dataset_root/val/**: éªŒè¯é›†æ•°æ®ï¼Œç»“æ„ä¸è®­ç»ƒé›†ç›¸åŒ
- **dataset_root/test_data/**: ç”¨äºå¿«é€ŸéªŒè¯çš„æµ‹è¯•æ•°æ®ï¼ˆ1ä¸ªæ ·æœ¬ï¼‰
- **dataset_mini/**: è¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ŒåŒ…å«ç¨‹åºç”Ÿæˆçš„éšæœºæµ‹è¯•å›¾ç‰‡ï¼ˆ21å¼ ï¼‰ï¼Œç”¨äºå¿«é€ŸéªŒè¯æ•°æ®æµç¨‹
- **processed_dataset_seq/**: å¤„ç†åçš„ HuggingFace Dataset æ ¼å¼æ•°æ®é›†ï¼Œæ”¯æŒå¤šå¸§è¾“å…¥åºåˆ—ï¼ˆ`input_frames: List[str]`ï¼Œå…ƒç´ ä¸ºå¸§è·¯å¾„ï¼‰
- **processed_dataset_mini_test/**: æ—§ç‰ˆå¤„ç†åçš„æ•°æ®é›†ï¼ˆå•å¸§è¾“å…¥æ ¼å¼ï¼Œå·²åºŸå¼ƒï¼‰
- **models/instruct-pix2pix/**: é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ€»å¤§å°çº¦ 2.4GB
- **test_output/**: æµ‹è¯•è®­ç»ƒçš„è¾“å‡ºï¼ŒåŒ…å«æ£€æŸ¥ç‚¹å’Œæœ€ç»ˆæ¨¡å‹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### ä½¿ç”¨ Condaï¼ˆæ¨èï¼‰

```bash
# å¦‚æœæ²¡æœ‰ç¯å¢ƒï¼Œåˆ›å»ºæ–°ç¯å¢ƒ
conda create -n dl-final python=3.10
conda activate dl-final
```

#### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

#### æ–¹å¼ 1: ä½¿ç”¨ä¸‹è½½è„šæœ¬ï¼ˆæ¨èï¼Œå·²é…ç½®é•œåƒï¼‰

```bash
# ä½¿ç”¨ HF-Mirror é•œåƒç«™ç‚¹ï¼ˆå›½å†…é€Ÿåº¦å¿«ï¼‰
export HF_ENDPOINT=https://hf-mirror.com
python download_model.py
```

#### æ–¹å¼ 2: æ‰‹åŠ¨ä¸‹è½½

è¯¦è§ [MODEL_DOWNLOAD.md](MODEL_DOWNLOAD.md)

### 3. å‡†å¤‡æµ‹è¯•æ•°æ®

#### æ–¹å¼ 1: åˆ›å»ºè¿·ä½ æµ‹è¯•æ•°æ®é›†å¹¶è½¬æ¢ä¸º HuggingFace æ ¼å¼ï¼ˆæ¨èï¼‰

```bash
# æ­¥éª¤ 1: ç”Ÿæˆè¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ˆåŒ…å«21å¼ éšæœºç”Ÿæˆçš„æµ‹è¯•å›¾ç‰‡ï¼‰
python create_mini_data.py

# æ­¥éª¤ 2: è½¬æ¢ä¸º HuggingFace Dataset æ ¼å¼ï¼ˆæ”¯æŒå¤šå¸§è¾“å…¥åºåˆ—ï¼‰
python make_dataset.py
```

è¿™ä¼šåˆ›å»ºï¼š
- `dataset_mini/`: åŸå§‹æµ‹è¯•æ•°æ®ï¼ˆ21å¼ å›¾ç‰‡ï¼Œ00.jpg åˆ° 20.jpgï¼‰
- `processed_dataset_seq/`: HuggingFace Dataset æ ¼å¼æ•°æ®é›†
  - ç‰¹å¾ï¼š`input_frames` (List[Image], 20å¸§), `edit_prompt` (string), `edited_image` (Image)

**æ³¨æ„**ï¼š`make_dataset.py` æ”¯æŒå¤šå¸§è¾“å…¥åºåˆ—ï¼Œå°† 00.jpg-19.jpg ä½œä¸ºè¾“å…¥å¸§ï¼Œ20.jpg ä½œä¸ºç›®æ ‡è¾“å‡ºã€‚

#### æ–¹å¼ 2: å‡†å¤‡çœŸå®æµ‹è¯•æ•°æ®

```bash
# å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆä» test_video ç›®å½•ï¼‰
python prepare_test_data.py
```

### 4. è¿è¡Œæµ‹è¯•è®­ç»ƒ

```bash
# è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆ5æ­¥è®­ç»ƒï¼ŒéªŒè¯ç¯å¢ƒæ˜¯å¦æ­£ç¡®ï¼‰
bash test_training.sh
```

### 5. ä½¿ç”¨ Python å¯åŠ¨è§†é¢‘è®­ç»ƒï¼ˆæ¨èï¼‰

æ— éœ€æ‰‹åŠ¨è¾“å…¥ `accelerate launch ...`ï¼Œå¯ç›´æ¥è¿è¡Œï¼š

```bash
python run_video_training.py
```

è¯´æ˜ï¼š
- è„šæœ¬å†…éƒ¨è°ƒç”¨ `accelerate.notebook_launcher`ï¼Œé»˜è®¤å¯åŠ¨ 4 ä¸ªè¿›ç¨‹ï¼ˆå¯é€šè¿‡ `VIDEO_TRAIN_PROCESSES` ç¯å¢ƒå˜é‡è°ƒæ•´ï¼Œå¦‚ `export VIDEO_TRAIN_PROCESSES=1`ï¼‰ã€‚
- æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°é›†ä¸­åœ¨ `run_video_training.py` çš„ `TRAINING_ARG_LIST` ä¸­ï¼Œå¯æŒ‰éœ€ä¿®æ”¹ã€‚
- å¯åŠ¨æ—¶ä¼šå¼ºåˆ¶æŠŠå¤šè¿›ç¨‹æ¨¡å¼åˆ‡æ¢ä¸º `spawn`ï¼Œé¿å… CUDA fork å­è¿›ç¨‹æ—¶æŠ¥ â€œCannot re-initialize CUDA in forked subprocessâ€ã€‚
- è‹¥éœ€è¦æ¢å¤å‘½ä»¤è¡Œç”¨æ³•ï¼Œ`train_video_ip2p.py` ä»ç„¶æ”¯æŒ `accelerate launch`ã€‚

### 6. å®Œæ•´è®­ç»ƒ

```bash
# ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
python train_instruct_pix2pix.py \
    --pretrained_model_name_or_path dl-final/models/instruct-pix2pix \
    --train_data_dir dl-final/dataset_root/train \
    --original_image_column input_image \
    --edit_prompt_column edit_prompt \
    --edited_image_column edited_image \
    --resolution 256 \
    --train_batch_size 4 \
    --num_train_epochs 100 \
    --learning_rate 1e-4 \
    --output_dir dl-final/output \
    --mixed_precision fp16 \
    --checkpointing_steps 500
```

## ğŸ“¦ ä¾èµ–è¯´æ˜

ä¸»è¦ä¾èµ–åŒ…ï¼š

- **accelerate**: åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- **diffusers**: HuggingFace æ‰©æ•£æ¨¡å‹åº“
- **transformers**: HuggingFace æ¨¡å‹åº“
- **torch**: PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- **datasets**: HuggingFace æ•°æ®é›†åº“
- **wandb**: å®éªŒè·Ÿè¸ªï¼ˆå¯é€‰ï¼‰

å®Œæ•´ä¾èµ–åˆ—è¡¨è§ [requirements.txt](requirements.txt)

## ğŸ”§ é…ç½®è¯´æ˜

### ä½¿ç”¨é•œåƒç«™ç‚¹ï¼ˆåŠ é€Ÿä¸‹è½½ï¼‰

```bash
# è®¾ç½® HF-Mirror é•œåƒï¼ˆæ¨èï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–ä½¿ç”¨å®˜æ–¹ç«™ç‚¹
export HF_ENDPOINT=https://huggingface.co
```

### ä¿®å¤ Protobuf å…¼å®¹æ€§é—®é¢˜

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

# æˆ–é™çº§ protobuf
pip install "protobuf<=3.20.3"
```

## ğŸ“Š æ•°æ®é›†æ ¼å¼

### åŸå§‹æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®éœ€è¦éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š

#### ç›®å½•ç»“æ„

```
dataset_root/
â”œâ”€â”€ metadata.jsonl    # å…ƒæ•°æ®æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
â”œâ”€â”€ image1.jpg        # å›¾åƒæ–‡ä»¶
â”œâ”€â”€ image2.jpg
â””â”€â”€ ...
```

#### metadata.jsonl æ ¼å¼ï¼ˆå•å¸§è¾“å…¥ï¼‰

æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
  "file_name": "input_image.jpg",
  "input_image": "input_image.jpg",
  "edit_prompt": "dropping betel onto the chair",
  "edited_image": "edited_image.jpg"
}
```

- `file_name`: ä¸»å›¾åƒæ–‡ä»¶åï¼ˆimagefolder æ ¼å¼è¦æ±‚ï¼‰
- `input_image`: åŸå§‹å›¾åƒæ–‡ä»¶å
- `edit_prompt`: ç¼–è¾‘æŒ‡ä»¤æ–‡æœ¬
- `edited_image`: ç¼–è¾‘åçš„å›¾åƒæ–‡ä»¶å

### å¤šå¸§è¾“å…¥åºåˆ—æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰

å¯¹äºæ”¯æŒå¤šå¸§è¾“å…¥çš„æ•°æ®ï¼ˆå¦‚è§†é¢‘åºåˆ—ï¼‰ï¼Œä½¿ç”¨ `make_dataset.py` è½¬æ¢ä¸º HuggingFace Dataset æ ¼å¼ï¼š

#### åŸå§‹æ•°æ®ç›®å½•ç»“æ„

```
dataset_mini/
â”œâ”€â”€ metadata.json              # å…ƒæ•°æ®æ–‡ä»¶
â””â”€â”€ train/
    â””â”€â”€ video_test_01/         # è§†é¢‘ç›®å½•
        â”œâ”€â”€ 00.jpg             # ç¬¬1å¸§ï¼ˆè¾“å…¥ï¼‰
        â”œâ”€â”€ 01.jpg             # ç¬¬2å¸§ï¼ˆè¾“å…¥ï¼‰
        â”œâ”€â”€ ...
        â”œâ”€â”€ 19.jpg             # ç¬¬20å¸§ï¼ˆè¾“å…¥ï¼‰
        â””â”€â”€ 20.jpg             # ç¬¬21å¸§ï¼ˆç›®æ ‡è¾“å‡ºï¼‰
```

#### metadata.json æ ¼å¼ï¼ˆå¤šå¸§è¾“å…¥ï¼‰

```json
[
  {
    "video_path": "train/video_test_01",
    "instruction": "move the object to the right"
  }
]
```

- `video_path`: è§†é¢‘ç›®å½•çš„ç›¸å¯¹è·¯å¾„
- `instruction`: ç¼–è¾‘æŒ‡ä»¤æ–‡æœ¬

#### è½¬æ¢åçš„ HuggingFace Dataset æ ¼å¼

ä½¿ç”¨ `make_dataset.py` è½¬æ¢åï¼Œç”Ÿæˆçš„æ•°æ®é›†åŒ…å«ä»¥ä¸‹ç‰¹å¾ï¼ˆå¸§ä»¥è·¯å¾„å­—ç¬¦ä¸²å­˜å‚¨ï¼Œè®­ç»ƒæ—¶å†è¯»å–å›¾ç‰‡ï¼‰ï¼š

```python
Features({
    "input_frames": Sequence(Value("string")),  # å¤šå¸§è¾“å…¥ï¼ˆ20å¸§ï¼š00.jpg-19.jpgè·¯å¾„ï¼‰
    "edit_prompt": Value("string"),             # ç¼–è¾‘æŒ‡ä»¤
    "edited_image": Image(),                    # ç›®æ ‡è¾“å‡ºï¼ˆ20.jpgï¼‰
})
```

**æ³¨æ„**ï¼š`input_frames` çš„å…ƒç´ æ˜¯å¸§è·¯å¾„å­—ç¬¦ä¸²ï¼ˆSequence(Value("string"))ï¼‰ï¼Œè®­ç»ƒè„šæœ¬ä¼šåœ¨è¯»å– batch æ—¶ç”¨ PIL æ‰“å¼€å¹¶è½¬æ¢ã€‚

## ğŸ¯ è®­ç»ƒå‚æ•°è¯´æ˜

### ä¸»è¦å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--pretrained_model_name_or_path` | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ | å¿…éœ€ |
| `--train_data_dir` | è®­ç»ƒæ•°æ®ç›®å½• | å¿…éœ€ |
| `--output_dir` | è¾“å‡ºç›®å½• | `instruct-pix2pix-model` |
| `--resolution` | å›¾åƒåˆ†è¾¨ç‡ | `256` |
| `--train_batch_size` | æ‰¹æ¬¡å¤§å° | `16` |
| `--num_train_epochs` | è®­ç»ƒè½®æ•° | `100` |
| `--learning_rate` | å­¦ä¹ ç‡ | `1e-4` |
| `--mixed_precision` | æ··åˆç²¾åº¦ | `fp16` |
| `--checkpointing_steps` | æ£€æŸ¥ç‚¹ä¿å­˜æ­¥æ•° | `500` |

### æ•°æ®åˆ—åå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--original_image_column` | åŸå§‹å›¾åƒåˆ—å | `input_image` |
| `--edit_prompt_column` | ç¼–è¾‘æŒ‡ä»¤åˆ—å | `edit_prompt` |
| `--edited_image_column` | ç¼–è¾‘åå›¾åƒåˆ—å | `edited_image` |

å®Œæ•´å‚æ•°åˆ—è¡¨ï¼š

```bash
python train_instruct_pix2pix.py --help
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### åˆ›å»ºè¿·ä½ æµ‹è¯•æ•°æ®é›†å¹¶è½¬æ¢

```bash
# æ­¥éª¤ 1: ç”Ÿæˆè¿·ä½ æµ‹è¯•æ•°æ®é›†ï¼ˆç”¨äºå¿«é€ŸéªŒè¯æ•°æ®æµç¨‹ï¼‰
python create_mini_data.py

# æ­¥éª¤ 2: è½¬æ¢ä¸º HuggingFace Dataset æ ¼å¼
python make_dataset.py
```

**è¯´æ˜**ï¼š
- `create_mini_data.py` ç”Ÿæˆï¼š
  - 21 å¼ éšæœºæµ‹è¯•å›¾ç‰‡ï¼ˆ00.jpg åˆ° 20.jpgï¼‰
  - å›¾ç‰‡å°ºå¯¸ï¼š128x128 åƒç´ 
  - å›¾ç‰‡ç±»å‹ï¼šéšæœºå™ªç‚¹å›¾ï¼ˆç¨‹åºè‡ªåŠ¨ç”Ÿæˆï¼ŒéçœŸå®è§†é¢‘å¸§ï¼‰
  - è¾“å‡ºç›®å½•ï¼š`dataset_mini/`
  - åŒ…å« `metadata.json` ç´¢å¼•æ–‡ä»¶

- `make_dataset.py` è½¬æ¢ï¼š
  - è¾“å…¥ï¼š`dataset_mini/`ï¼ˆåŸå§‹æ•°æ®ï¼‰
  - è¾“å‡ºï¼š`processed_dataset_seq_test/`ï¼ˆHuggingFace Dataset æ ¼å¼ï¼‰
  - ç‰¹å¾ï¼š`input_frames` (20å¸§), `edit_prompt`, `edited_image`
  - é…ç½®ï¼šå¯åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `DATA_ROOT` å’Œ `OUTPUT_DIR`

### éªŒè¯æ•°æ®é›†æ ¼å¼

```bash
# éªŒè¯è½¬æ¢åçš„æ•°æ®é›†
python -c "from datasets import load_from_disk; ds = load_from_disk('processed_dataset_seq'); print('æ•°æ®é›†å¤§å°:', len(ds['train'])); print('ç‰¹å¾:', ds['train'].features)"
```

### å¿«é€Ÿæµ‹è¯•æ•°æ®æ ¼å¼

```bash
python quick_test.py
```

### è¿è¡Œæµ‹è¯•è®­ç»ƒ

```bash
bash test_training.sh
```

æµ‹è¯•è®­ç»ƒä¼šï¼š
- ä½¿ç”¨æµ‹è¯•æ•°æ®ï¼ˆ1ä¸ªæ ·æœ¬ï¼‰
- è®­ç»ƒ 5 æ­¥
- éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
- ä¿å­˜æ£€æŸ¥ç‚¹åˆ° `test_output/`

## ğŸ“ è®­ç»ƒæ—¥å¿—

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ï¼š

- TensorBoard: `{output_dir}/logs/`
- WandB: å¦‚æœé…ç½®äº† `--report_to wandb`

æŸ¥çœ‹ TensorBoardï¼š

```bash
tensorboard --logdir dl-final/test_output/logs
```

## ğŸ” å¸¸è§é—®é¢˜

### 1. æ¨¡å‹ä¸‹è½½å¤±è´¥

**é—®é¢˜**: æ— æ³•ä» HuggingFace Hub ä¸‹è½½æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨é•œåƒç«™ç‚¹ï¼š`export HF_ENDPOINT=https://hf-mirror.com`
- æ‰‹åŠ¨ä¸‹è½½åä½¿ç”¨æœ¬åœ°è·¯å¾„
- æ£€æŸ¥ç½‘ç»œè¿æ¥

### 2. Protobuf ç‰ˆæœ¬å†²çª

**é—®é¢˜**: `TypeError: Descriptors cannot not be created directly`

**è§£å†³æ–¹æ¡ˆ**:
```bash
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
pip install "protobuf<=3.20.3"
```

### 3. CUDA å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- å‡å° `--train_batch_size`
- å¯ç”¨ `--gradient_checkpointing`
- ä½¿ç”¨ `--mixed_precision fp16` æˆ– `bf16`
- å®‰è£… xformers: `pip install xformers` å¹¶ä½¿ç”¨ `--enable_xformers_memory_efficient_attention`

### 4. æ•°æ®æ ¼å¼é”™è¯¯

**é—®é¢˜**: `ValueError: file_name must be present`

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®ä¿ `metadata.jsonl` åŒ…å« `file_name` å­—æ®µ
- æ£€æŸ¥å›¾åƒæ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- è¿è¡Œ `python quick_test.py` éªŒè¯æ•°æ®æ ¼å¼

### 5. æ•°æ®é›†è½¬æ¢é—®é¢˜

**é—®é¢˜**: `FileNotFoundError: No such file or directory`

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ˆ`make_dataset.py` å·²è‡ªåŠ¨å¤„ç†ï¼‰
- æ£€æŸ¥ `dataset_mini/metadata.json` ä¸­çš„è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®ä¿æ‰€æœ‰å¸§æ–‡ä»¶ï¼ˆ00.jpg-20.jpgï¼‰éƒ½å­˜åœ¨
- è¿è¡Œ `python make_dataset.py` æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯

**é—®é¢˜**: æ•°æ®é›† features ä¸­æ˜¾ç¤º `List` è€Œä¸æ˜¯ `Sequence`

**è¯´æ˜**:
- JSON åºåˆ—åŒ–æ—¶ `Sequence(Value("string"))` ä¼šä»¥ `List` å½¢å¼å‡ºç°
- `List` å’Œ `Sequence` åœ¨ HuggingFace datasets ä¸­åŠŸèƒ½ç­‰ä»·
- å¯ä»¥é€šè¿‡ `ds['train'].features` éªŒè¯å®é™…ç±»å‹ï¼Œå¹¶ç¡®è®¤ `input_frames` çš„å…ƒç´ æ˜¯å­—ç¬¦ä¸²

## ğŸ“š å‚è€ƒèµ„æ–™

- [InstructPix2Pix è®ºæ–‡](https://arxiv.org/abs/2211.09800)
- [HuggingFace Diffusers æ–‡æ¡£](https://huggingface.co/docs/diffusers)
- [æ¨¡å‹ä¸‹è½½è¯´æ˜](MODEL_DOWNLOAD.md)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº HuggingFace Diffusers çš„ InstructPix2Pix è®­ç»ƒè„šæœ¬ï¼Œéµå¾ª Apache 2.0 è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

**æœ€åæ›´æ–°**: 2025-12-02

**æ›´æ–°å†…å®¹**:
- âœ… æ·»åŠ å¤šå¸§è¾“å…¥åºåˆ—æ”¯æŒï¼ˆ`make_dataset.py`ï¼Œå¸§è·¯å¾„å­˜å‚¨ä¸ºå­—ç¬¦ä¸²åºåˆ—ï¼‰
- âœ… æ–°å¢ `run_video_training.py`ï¼Œæ”¯æŒçº¯ Python å¯åŠ¨è®­ç»ƒ
- âœ… æ›´æ–°æ•°æ®é›†è½¬æ¢æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜

